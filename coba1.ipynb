{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81dd91b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 2,
>>>>>>> b82b2be (coba)
   "id": "c1e2886c",
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20.0\n"
=======
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
>>>>>>> b82b2be (coba)
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70093499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.4641, Test Acc: 0.8655\n",
      "Epoch 2/5, Loss: 0.5041, Test Acc: 0.8975\n",
      "Epoch 3/5, Loss: 0.3448, Test Acc: 0.9097\n",
      "Epoch 4/5, Loss: 0.2436, Test Acc: 0.9172\n",
      "Epoch 5/5, Loss: 0.1319, Test Acc: 0.9237\n"
     ]
    }
   ],
   "source": [
    "# MLP dengan numpy\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 1. Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28*28).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(-1, 28*28).astype(\"float32\") / 255.0\n",
    "\n",
    "# One-hot encoding label\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# 2. Inisialisasi parameter MLP\n",
    "input_dim = 784   # 28*28\n",
    "hidden_dim = 128\n",
    "output_dim = 10\n",
    "lr = 0.01\n",
    "\n",
    "# Bobot dan bias\n",
    "W1 = np.random.randn(input_dim, hidden_dim) * 0.01\n",
    "b1 = np.zeros((1, hidden_dim))\n",
    "W2 = np.random.randn(hidden_dim, output_dim) * 0.01\n",
    "b2 = np.zeros((1, output_dim))\n",
    "\n",
    "# Fungsi aktivasi\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "# Loss: cross-entropy\n",
    "def cross_entropy(y_true, y_pred):\n",
    "    m = y_true.shape[0]\n",
    "    return -np.sum(y_true * np.log(y_pred + 1e-9)) / m\n",
    "\n",
    "# 3. Training loop\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Shuffle data\n",
    "    idx = np.random.permutation(len(x_train))\n",
    "    x_train, y_train = x_train[idx], y_train[idx]\n",
    "\n",
    "    for i in range(0, len(x_train), batch_size):\n",
    "        X_batch = x_train[i:i+batch_size]\n",
    "        Y_batch = y_train[i:i+batch_size]\n",
    "\n",
    "        # Forward pass\n",
    "        Z1 = np.dot(X_batch, W1) + b1\n",
    "        A1 = relu(Z1)\n",
    "        Z2 = np.dot(A1, W2) + b2\n",
    "        A2 = softmax(Z2)\n",
    "\n",
    "        # Loss\n",
    "        loss = cross_entropy(Y_batch, A2)\n",
    "\n",
    "        # Backward pass\n",
    "        dZ2 = A2 - Y_batch\n",
    "        dW2 = np.dot(A1.T, dZ2) / batch_size\n",
    "        db2 = np.sum(dZ2, axis=0, keepdims=True) / batch_size\n",
    "\n",
    "        dA1 = np.dot(dZ2, W2.T)\n",
    "        dZ1 = dA1 * relu_derivative(Z1)\n",
    "        dW1 = np.dot(X_batch.T, dZ1) / batch_size\n",
    "        db1 = np.sum(dZ1, axis=0, keepdims=True) / batch_size\n",
    "\n",
    "        # Update parameter\n",
    "        W1 -= lr * dW1\n",
    "        b1 -= lr * db1\n",
    "        W2 -= lr * dW2\n",
    "        b2 -= lr * db2\n",
    "\n",
    "    # Evaluasi tiap epoch\n",
    "    Z1 = np.dot(x_test, W1) + b1\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    A2 = softmax(Z2)\n",
    "\n",
    "    acc = np.mean(np.argmax(A2, axis=1) == np.argmax(y_test, axis=1))\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}, Test Acc: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e52c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 3s 0us/step\n",
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 15s 8ms/step - loss: 0.2739 - accuracy: 0.9209 - val_loss: 0.1318 - val_accuracy: 0.9645\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 13s 8ms/step - loss: 0.1201 - accuracy: 0.9644 - val_loss: 0.0952 - val_accuracy: 0.9727\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.0817 - accuracy: 0.9753 - val_loss: 0.0893 - val_accuracy: 0.9745\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.0617 - accuracy: 0.9817 - val_loss: 0.0720 - val_accuracy: 0.9763\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.0471 - accuracy: 0.9856 - val_loss: 0.0976 - val_accuracy: 0.9717\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0969 - accuracy: 0.9709\n",
      "Test accuracy: 0.9708999991416931\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# MLP Keras/TensorFlow \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.datasets import mnist \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Flatten \n",
    "from tensorflow.keras.utils import to_categorical \n",
    "\n",
    " \n",
    "\n",
    "# 1. Load dataset \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data() \n",
    "x_train = x_train.astype(\"float32\") / 255.0 \n",
    "x_test = x_test.astype(\"float32\") / 255.0 \n",
    "\n",
    " \n",
    "\n",
    "# One-hot encoding label \n",
    "y_train = to_categorical(y_train, 10) \n",
    "y_test = to_categorical(y_test, 10) \n",
    "\n",
    " \n",
    "\n",
    "# 2. Bangun MLP \n",
    "\n",
    "model = Sequential([ \n",
    "    Flatten(input_shape=(28,28)), \n",
    "    Dense(128, activation=\"relu\"), \n",
    "    Dense(10, activation=\"softmax\") \n",
    "]) \n",
    "\n",
    " \n",
    "\n",
    "# 3. Compile & train \n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]) \n",
    "history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.1) \n",
    "\n",
    " \n",
    "\n",
    "# 4. Evaluasi \n",
    "test_loss, test_acc = model.evaluate(x_test, y_test) \n",
    "print(\"Test accuracy:\", test_acc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9373a2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1688/1688 [==============================] - 71s 41ms/step - loss: 0.1371 - accuracy: 0.9577 - val_loss: 0.0505 - val_accuracy: 0.9847\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 70s 41ms/step - loss: 0.0453 - accuracy: 0.9858 - val_loss: 0.0412 - val_accuracy: 0.9872\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 70s 41ms/step - loss: 0.0306 - accuracy: 0.9906 - val_loss: 0.0400 - val_accuracy: 0.9888\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 70s 41ms/step - loss: 0.0227 - accuracy: 0.9925 - val_loss: 0.0400 - val_accuracy: 0.9900\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 71s 42ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.0438 - val_accuracy: 0.9902\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.0369 - accuracy: 0.9896\n",
      "Test accuracy CNN: 0.9896000027656555\n"
     ]
    }
   ],
   "source": [
    "# CNN untuk MNIST \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.datasets import mnist \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense \n",
    "from tensorflow.keras.utils import to_categorical \n",
    "\n",
    "# 1. Load dataset \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data() \n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0 \n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0 \n",
    "\n",
    "y_train = to_categorical(y_train, 10) \n",
    "y_test = to_categorical(y_test, 10) \n",
    "\n",
    "# 2. Bangun CNN \n",
    "\n",
    "model = Sequential([ \n",
    "    Conv2D(32, kernel_size=(3,3), activation=\"relu\", input_shape=(28,28,1)), \n",
    "    MaxPooling2D(pool_size=(2,2)), \n",
    "    Conv2D(64, kernel_size=(3,3), activation=\"relu\"), \n",
    "    MaxPooling2D(pool_size=(2,2)), \n",
    "    Flatten(), \n",
    "    Dense(128, activation=\"relu\"), \n",
    "    Dense(10, activation=\"softmax\") \n",
    "]) \n",
    "\n",
    " \n",
    "\n",
    "# 3. Compile & train \n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]) \n",
    "history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.1) \n",
    " \n",
    "\n",
    "# 4. Evaluasi \n",
    "test_loss, test_acc = model.evaluate(x_test, y_test) \n",
    "print(\"Test accuracy CNN:\", test_acc) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb00596",
   "metadata": {},
   "source": [
    "**alur MNIST** dengan tiga pendekatan berbeda:  \n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ MLP dengan NumPy (manual)\n",
    "- **Dataset MNIST**: gambar angka 28√ó28 ‚Üí di-*flatten* jadi vektor 784.\n",
    "- **Forward pass**:\n",
    "  - \\(Z_1 = X W_1 + b_1\\), lalu aktivasi ReLU ‚Üí \\(A_1\\).\n",
    "  - \\(Z_2 = A_1 W_2 + b_2\\), lalu softmax ‚Üí \\(A_2\\).\n",
    "- **Loss**: cross-entropy menghitung seberapa jauh prediksi dari label asli.\n",
    "- **Backward pass**: hitung gradien (turunan) untuk bobot dan bias.\n",
    "- **Update parameter**: \\(W \\leftarrow W - \\eta \\cdot dW\\).\n",
    "- **Intuisi**: seperti otak buatan yang belajar dari kesalahan, memperbaiki bobot sedikit demi sedikit.\n",
    "\n",
    "üëâ Di sini semua rumus ditulis manual dengan NumPy, sehingga kita benar-benar melihat proses matematis di balik MLP.\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ MLP dengan TensorFlow/Keras\n",
    "- **Dataset MNIST**: otomatis di-*flatten* oleh `Flatten(input_shape=(28,28))`.\n",
    "- **Arsitektur**:\n",
    "  - Dense(128, activation=\"relu\")\n",
    "  - Dense(10, activation=\"softmax\")\n",
    "- **Compile**: optimizer Adam, loss categorical crossentropy.\n",
    "- **Fit**: training dilakukan otomatis, TensorFlow yang mengurus forward, backward, dan update parameter.\n",
    "- **Intuisi**: kita tidak perlu menulis rumus gradien, karena library sudah menyediakan. Fokus kita hanya pada desain arsitektur.\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ CNN dengan TensorFlow (lebih canggih)\n",
    "CNN lebih cocok untuk data gambar karena bisa menangkap **pola lokal**.\n",
    "\n",
    "### üîπ Conv2D\n",
    "- **Prinsip**: filter 3√ó3 menyapu gambar, mendeteksi pola kecil (tepi, sudut, lengkung).\n",
    "- **Parameter**: tiap filter punya bobot 3√ó3√óchannel_in + bias.\n",
    "  - Contoh: 32 filter, input 1 channel ‚Üí \\(32 \\times (3 \\times 3 \\times 1 + 1) = 320\\).\n",
    "- **Operasi**:  \n",
    "  \\[\n",
    "  y(i,j,f) = \\sum_{u=0}^{k-1}\\sum_{v=0}^{k-1}\\sum_{c=0}^{C-1} W_{u,v,c}^{(f)} \\cdot x(i+u, j+v, c) + b^{(f)}\n",
    "  \\]\n",
    "- **Aktivasi ReLU**: \\(\\text{ReLU}(z) = \\max(0,z)\\).\n",
    "\n",
    "### üîπ ReLU\n",
    "- **Fungsi**: membuang nilai negatif ‚Üí hanya fitur ‚Äúaktif‚Äù.\n",
    "- **Manfaat**: mempercepat konvergensi, mencegah gradien hilang.\n",
    "\n",
    "### üîπ MaxPooling2D\n",
    "- **Prinsip**: ambil nilai maksimum dalam jendela 2√ó2.\n",
    "- **Manfaat**: mengecilkan resolusi, menyaring noise, membuat fitur lebih tahan terhadap pergeseran.\n",
    "\n",
    "### üîπ Conv2D kedua (64 filter)\n",
    "- **Peran**: menggabungkan fitur level-1 (tepi) menjadi motif level-2 (lengkung angka).\n",
    "- **Parameter**: \\(64 \\times (3 \\times 3 \\times 32 + 1) = 18{,}496\\).\n",
    "\n",
    "### üîπ Flatten\n",
    "- **Fungsi**: ubah peta fitur 2D menjadi vektor 1D.\n",
    "- **Tujuan**: agar bisa masuk ke lapisan dense untuk klasifikasi.\n",
    "\n",
    "### üîπ Dense 128 (ReLU)\n",
    "- **Peran**: menggabungkan semua fitur global.\n",
    "- **Parameter**: \\(1600 \\times 128 + 128 = 204{,}928\\).\n",
    "\n",
    "### üîπ Dense 10 (Softmax)\n",
    "- **Fungsi**: menghasilkan probabilitas untuk 10 kelas digit.\n",
    "- **Rumus**:  \n",
    "  \\[\n",
    "  p_k = \\frac{e^{z_k}}{\\sum_{j=1}^{10} e^{z_j}}\n",
    "  \\]\n",
    "- **Makna**: distribusi probabilitas, dipakai dengan loss categorical crossentropy.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ú® Ringkasan intuitif\n",
    "- **MLP NumPy** ‚Üí belajar manual, kita hitung semua rumus sendiri.  \n",
    "- **MLP TensorFlow** ‚Üí lebih praktis, library mengurus detail matematis.  \n",
    "- **CNN TensorFlow** ‚Üí lebih kuat untuk gambar, karena bisa menangkap pola lokal (tepi, lengkung) lalu menggabungkannya menjadi fitur kompleks sebelum klasifikasi.  \n",
    "\n",
    "---\n",
    "\n",
    "Kalau mau lebih visual, saya bisa buat **diagram alur perbedaan MLP vs CNN** sehingga terlihat jelas bagaimana data gambar mengalir dari input ‚Üí hidden ‚Üí output. Mau saya buatkan diagram itu?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.10.4"
=======
   "version": "3.10.14"
>>>>>>> b82b2be (coba)
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
